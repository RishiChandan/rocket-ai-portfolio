# ðŸš€ Rocket AI Portfolio Assistant

![Render](https://img.shields.io/badge/Backend-Render-blue?logo=render)  
![Vercel](https://img.shields.io/badge/Frontend-Vercel-black?logo=vercel)

Your personal AI-powered portfolio assistant built with **GPT-4**, **LangChain**, **ChromaDB**, and a full **RAG (Retrieval-Augmented Generation)** pipeline. Ask *Rocket* about your resume, background, or experience â€” it fetches answers straight from your actual resume using intelligent retrieval!

---

## ðŸŒ Live Demo

- [https://rocket-ai-portfolio.vercel.app/]
  
---

## âœ¨ Features

- ðŸ¤– **Chat-based AI assistant** powered by GPT-4
- ðŸ“„ Parses resume PDF from Google Drive
- ðŸ§  ChromaDB vector store for persistent embeddings
- ðŸ” LangChain `RetrievalQA` for smart answers
- âš™ï¸ Auto-rebuilds vectorstore on first deploy
- ðŸ§  Answers questions based on actual resume content

---

## ðŸ§° Tech Stack

### ðŸ”™ Backend (`rocket-rag-backend`)
- `FastAPI` + `Uvicorn`
- `LangChain`, `LangChain-Community`, `LangChain-OpenAI`
- `OpenAIEmbeddings`, `ChatOpenAI`
- `ChromaDB` for vector storage
- `PyPDFLoader` for light PDF parsing
- Hosted on **Render**

### ðŸŒ Frontend (`rocket-frontend`)
- `React.js` + `Tailwind CSS`
- Typing animation (`react-simple-typewriter`)
- Hosted on **Vercel**

---

## ðŸ“„ Resume Integration

- ðŸ” Loaded via `PyPDFLoader` from public Google Drive link
- ðŸ§  Embedded using OpenAI + stored in ChromaDB
- âš¡ Automatically persists to avoid repeated loads

---

## ðŸ” Environment Variables

### âœ… Backend (Render)
| Key              | Description                    |
|------------------|--------------------------------|
| `OPENAI_API_KEY` | OpenAI API Key for GPT-4 usage |

### âœ… Frontend (Vercel)
| Key                  | Description                         |
|----------------------|-------------------------------------|
| `REACT_APP_API_URL`  | Backend endpoint for `/ask` route   |

---

## ðŸ›  How to Run Locally

### ðŸ”™ Backend
```bash
cd rocket-rag-backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
uvicorn main:app --reload
```


## ðŸ§  RAG Pipeline Overview

1. ðŸ“„ PDF loaded from a **public Google Drive** link using `PyPDFLoader`
2. âœ‚ï¸ Text is split into document chunks
3. ðŸ§  Embeddings are generated using `OpenAIEmbeddings`
4. ðŸ’¾ Vectors are stored in **ChromaDB** (with persistent directory)
5. ðŸ” On user query, relevant chunks are retrieved
6. ðŸ¤– `ChatOpenAI` (GPT-4) answers using the retrieved context via `RetrievalQA`

---

## ðŸ‘¨â€ðŸ’» About the Creator

**Rishi Chandan**  
ðŸ› ï¸ Passionate about AI x UX x Products  
ðŸ”— [LinkedIn](https://www.linkedin.com/in/rishichandan/) â€¢ ðŸ’» [GitHub](https://github.com/RishiChandan)

> Building meaningful products with code, creativity, and coffee â˜•.

---

## ðŸ™Œ Credits

- ðŸ¤– Powered by **[OpenAI GPT-4](https://platform.openai.com/)** for LLM intelligence  
- ðŸ§  Built using **[LangChain](https://www.langchain.com/)** and `RetrievalQA`  
- ðŸ“Ž Document parsed via `PyPDFLoader` from `langchain_community`  
- ðŸ’¾ Vector storage handled by **[ChromaDB](https://www.trychroma.com/)**  
- ðŸš€ Hosted with â¤ï¸ on **[Render](https://render.com/)** (Backend) and **[Vercel](https://vercel.com/)** (Frontend)

> **Crafted to make portfolios intelligent. Inspired by the power of AI.**
